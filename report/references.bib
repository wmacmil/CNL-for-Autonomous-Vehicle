@InProceedings{brunello_et_al,
  author =	{Andrea Brunello and Angelo Montanari and Mark Reynolds},
  title =	{{Synthesis of LTL Formulas from Natural Language Texts: State of the Art and Research Directions}},
  booktitle =	{26th International Symposium on Temporal Representation and Reasoning (TIME 2019)},
  pages =	{17:1--17:19},
  series =	{Leibniz International Proceedings in Informatics (LIPIcs)},
  ISBN =	{978-3-95977-127-6},
  ISSN =	{1868-8969},
  year =	{2019},
  volume =	{147},
  editor =	{Johann Gamper and Sophie Pinchinat and Guido Sciavicco},
  publisher =	{Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{http://drops.dagstuhl.de/opus/volltexte/2019/11375},
  URN =		{urn:nbn:de:0030-drops-113756},
  doi =		{10.4230/LIPIcs.TIME.2019.17},
  annote =	{Keywords: Evolutionary algorithms, Machine learning, Natural language processing, Semantic parsing, Temporal logic}
}

@mastersthesis{macmillan2021,
    author = {Macmillan, Warrick},
    institution = {University of Gothenburg},
    school = {University of Gothenburg},
    pages = "90",
    title = {{On the Grammar of Proof}},
    year = {2021}
}

@misc{wltl,
  author = {Macmillan , Warrick and Kallberg , Andreas},
  title = {{LTL in Agda}},
  year = 2021,
  howpublished = {\url{https://github.com/wmacmil/LTL-Agda}}
}


@ARTICLE{coqLTL,
  author={Coupet-Grimal, Solange},
  journal={Journal of Logic and Computation}, 
  title={An Axiomatization of Linear Temporal Logic in the Calculus of Inductive Constructions}, 
  year={2003},
  volume={13},
  number={6},
  pages={801-813},
  doi={10.1093/logcom/13.6.801}}


@inproceedings{szegedy,
  author    = {Christian Szegedy and
               Wojciech Zaremba and
               Ilya Sutskever and
               Joan Bruna and
               Dumitru Erhan and
               Ian J. Goodfellow and
               Rob Fergus},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Intriguing properties of neural networks},
  booktitle = {2nd International Conference on Learning Representations, {ICLR} 2014,
               Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings},
  year      = {2014},
  url       = {http://arxiv.org/abs/1312.6199},
  timestamp = {Thu, 25 Jul 2019 14:35:25 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SzegedyZSBEGF13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{shakerin2020logic,
  title={Logic-Based Approaches in Explainable AI and Natural Language Understanding},
  author={Shakerin, Farhad},
  year={2020},
  publisher={The University of Texas at Dallas}
}

@inproceedings{basu2020aqua,
  title={Aqua: Asp-based visual question answering},
  author={Basu, Kinjal and Shakerin, Farhad and Gupta, Gopal},
  booktitle={International Symposium on Practical Aspects of Declarative Languages},
  pages={57--72},
  year={2020},
  organization={Springer}
}


@inproceedings{alzantot-etal-2018-generating,
    title = "Generating Natural Language Adversarial Examples",
    author = "Alzantot, Moustafa  and
      Sharma, Yash  and
      Elgohary, Ahmed  and
      Ho, Bo-Jhang  and
      Srivastava, Mani  and
      Chang, Kai-Wei",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1316",
    doi = "10.18653/v1/D18-1316",
    pages = "2890--2896",
    abstract = "Deep neural networks (DNNs) are vulnerable to adversarial examples, perturbations to correctly classified examples which can cause the model to misclassify. In the image domain, these perturbations can often be made virtually indistinguishable to human perception, causing humans and state-of-the-art models to disagree. However, in the natural language domain, small perturbations are clearly perceptible, and the replacement of a single word can drastically alter the semantics of the document. Given these challenges, we use a black-box population-based optimization algorithm to generate semantically and syntactically similar adversarial examples that fool well-trained sentiment analysis and textual entailment models with success rates of 97{\%} and 70{\%}, respectively. We additionally demonstrate that 92.3{\%} of the successful sentiment analysis adversarial examples are classified to their original label by 20 human annotators, and that the examples are perceptibly quite similar. Finally, we discuss an attempt to use adversarial training as a defense, but fail to yield improvement, demonstrating the strength and diversity of our adversarial examples. We hope our findings encourage researchers to pursue improving the robustness of DNNs in the natural language domain.",
}

@article{Adiwardana2020TowardsAH,
  title={Towards a Human-like Open-Domain Chatbot},
  author={Daniel De Freitas Adiwardana and Minh-Thang Luong and David R. So and Jamie Hall and Noah Fiedel and Romal Thoppilan and Zi Yang and Apoorv Kulshreshtha and Gaurav Nemade and Yifeng Lu and Quoc V. Le},
  journal={ArXiv},
  year={2020},
  volume={abs/2001.09977}
}

@inproceedings{katya13,
  author    = {Ekaterina Komendantskaya and
               J{\'{o}}nathan Heras and
               Gudmund Grov},
  editor    = {Cezary Kaliszyk and
               Christoph L{\"{u}}th},
  title     = {Machine Learning in Proof General: Interfacing Interfaces},
  booktitle = {Proceedings 10th International Workshop On User Interfaces for Theorem
               Provers, {UITP} 2012, Bremen, Germany, July 11th, 2012},
  series    = {{EPTCS}},
  volume    = {118},
  pages     = {15--41},
  year      = {2012},
  url       = {https://doi.org/10.4204/EPTCS.118.2},
  doi       = {10.4204/EPTCS.118.2},
  timestamp = {Wed, 12 Sep 2018 01:05:16 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1212-3618.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
